{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e55b6",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ðŸ“¦ Batch LLM Processor (Folders-as-Batches, Hidden Code, Drive Upload, Random Subset)\n",
    "#@markdown **Whatâ€™s new:** If your ZIP contains **subfolders**, each subfolder is processed as **one payload** (all files inside it are sent together).  \n",
    "#@markdown - Root-level files (not in any folder) are processed **one-by-one**.  \n",
    "#@markdown - A folder can contain a **mix of text + images**; they will be sent together in one request.  \n",
    "#@markdown **Note:** Big folders (many/large images) can exceed model or API limits.\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown **Instructions:**  \n",
    "#@markdown 1. Enter your **OpenRouter API Key**.  \n",
    "#@markdown 2. Enter a **System Prompt** (optional).  \n",
    "#@markdown 3. Choose or type a **Model ID**.  \n",
    "#@markdown 4. Provide your ZIP via **Upload** or **Google Drive path**.  \n",
    "#@markdown 5. (Optional) Tick the box to include inputs in output ZIP.  \n",
    "#@markdown 6. (Optional) Limit how many **items** are processed (items = folders + root files). Selection is random with a seed.  \n",
    "#@markdown 7. Click **Run Processing** and download results.\n",
    "\n",
    "import os, zipfile, base64, mimetypes, json, time, random\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from google.colab import files as colab_files, drive\n",
    "\n",
    "OPENROUTER_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "# --- UI Controls ---\n",
    "api_key = widgets.Password(description=\"API Key:\", layout=widgets.Layout(width=\"420px\"))\n",
    "system_prompt = widgets.Textarea(\n",
    "    description=\"System Prompt:\",\n",
    "    layout=widgets.Layout(width=\"650px\", height=\"90px\"),\n",
    "    placeholder=\"e.g., For each item, return a short description and tags.\"\n",
    ")\n",
    "\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"Gemini 2.5 Flash (default)\", \"google/gemini-2.5-flash\"),\n",
    "        (\"Gemini 2.5 Pro\", \"google/gemini-2.5-pro\"),\n",
    "        (\"GPT-5\", \"openai/gpt-5\"),\n",
    "        (\"GPT-5 Mini\", \"openai/gpt-5-mini\"),\n",
    "        (\"GPT-4.1\", \"openai/gpt-4.1\"),\n",
    "        (\"Claude Sonnet\", \"anthropic/claude-sonnet-4\"),\n",
    "        (\"Claude Opus\", \"anthropic/claude-opus-4.1\"),\n",
    "        (\"Mistral Medium 3.1\", \"mistralai/mistral-medium-3.1\"),\n",
    "        (\"Grok 4\", \"x-ai/grok-4\"),\n",
    "        (\"Grok 4 Fast\", \"x-ai/grok-4-fast\"),\n",
    "    ],\n",
    "    value=\"google/gemini-2.5-flash\",\n",
    "    description=\"Model:\"\n",
    ")\n",
    "\n",
    "model_custom = widgets.Text(\n",
    "    description=\"Custom Model:\",\n",
    "    placeholder=\"e.g. openai/gpt-4.1-mini\",\n",
    "    layout=widgets.Layout(width=\"520px\")\n",
    ")\n",
    "\n",
    "include_inputs = widgets.Checkbox(value=False, description=\"Include inputs in output zip\")\n",
    "\n",
    "upload_method = widgets.RadioButtons(\n",
    "    options=[\"Upload (<100MB)\", \"Google Drive path\"],\n",
    "    description=\"Input ZIP:\"\n",
    ")\n",
    "\n",
    "upload_btn = widgets.FileUpload(accept=\".zip\", multiple=False, description=\"Upload ZIP\")\n",
    "drive_path = widgets.Text(\n",
    "    description=\"Drive path:\",\n",
    "    placeholder=\"/content/drive/MyDrive/myfile.zip\",\n",
    "    layout=widgets.Layout(width=\"650px\")\n",
    ")\n",
    "\n",
    "max_items = widgets.IntText(value=0, description=\"Max items (0=all):\")\n",
    "seed_value = widgets.IntText(value=2025, description=\"Seed:\")\n",
    "\n",
    "run_btn = widgets.Button(description=\"Run Processing\", button_style=\"success\")\n",
    "\n",
    "ui_box = widgets.VBox([\n",
    "    api_key,\n",
    "    system_prompt,\n",
    "    model_dropdown,\n",
    "    model_custom,\n",
    "    include_inputs,\n",
    "    upload_method,\n",
    "    upload_btn,\n",
    "    drive_path,\n",
    "    widgets.HBox([max_items, seed_value]),\n",
    "    run_btn\n",
    "])\n",
    "display(ui_box)\n",
    "\n",
    "\n",
    "def _safe_list_zip_files(zf: zipfile.ZipFile):\n",
    "    \"\"\"Return a list of file entries in the zip (no directories), skipping common junk.\"\"\"\n",
    "    names = []\n",
    "    for n in zf.namelist():\n",
    "        if not n or n.endswith(\"/\"):\n",
    "            continue\n",
    "        # skip macOS resource forks / folders\n",
    "        if n.startswith(\"__MACOSX/\") or os.path.basename(n).startswith(\"._\"):\n",
    "            continue\n",
    "        names.append(n)\n",
    "    return names\n",
    "\n",
    "\n",
    "def _read_text_file(path: str) -> str:\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(path, \"r\", encoding=\"latin-1\") as f:\n",
    "            return f.read()\n",
    "\n",
    "\n",
    "def _build_groups(file_list):\n",
    "    \"\"\"Group files by folder. Root files each become their own group.\"\"\"\n",
    "    groups = {}\n",
    "    for rel in file_list:\n",
    "        rel = rel.replace(\"\\\\\", \"/\")\n",
    "        folder = os.path.dirname(rel)\n",
    "        if folder == \"\":\n",
    "            key = rel  # root-level file -> its own group\n",
    "        else:\n",
    "            key = folder  # folder group\n",
    "        groups.setdefault(key, []).append(rel)\n",
    "    # stable ordering\n",
    "    for k in groups:\n",
    "        groups[k] = sorted(groups[k])\n",
    "    return groups\n",
    "\n",
    "\n",
    "def _make_user_content_for_group(group_key: str, extracted_input_dir: str, members: list):\n",
    "    \"\"\"Create OpenRouter multimodal user content for a group (folder or single root file).\"\"\"\n",
    "    user_content = []\n",
    "    unsupported = []\n",
    "\n",
    "    # Add a small header so the model knows it's a batch\n",
    "    user_content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": f\"Batch item: {group_key}\\nFiles included: {len(members)}\\n\"\n",
    "    })\n",
    "\n",
    "    for rel_name in members:\n",
    "        fpath = os.path.join(extracted_input_dir, rel_name)\n",
    "        ext = os.path.splitext(rel_name)[1].lower()\n",
    "\n",
    "        if ext in [\".txt\", \".md\"]:\n",
    "            text = _read_text_file(fpath)\n",
    "            # include filename marker to keep texts distinct\n",
    "            user_content.append({\"type\": \"text\", \"text\": f\"--- FILE: {rel_name} ---\\n{text}\"})\n",
    "        elif ext in [\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\"]:\n",
    "            mime, _ = mimetypes.guess_type(fpath)\n",
    "            if mime is None:\n",
    "                mime = \"image/png\"\n",
    "            with open(fpath, \"rb\") as img_file:\n",
    "                img_b64 = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "            user_content.append({\"type\": \"text\", \"text\": f\"Image file: {rel_name}\"})\n",
    "            user_content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime};base64,{img_b64}\"}})\n",
    "        else:\n",
    "            unsupported.append(rel_name)\n",
    "\n",
    "    if unsupported:\n",
    "        user_content.append({\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Unsupported files (ignored):\\n\" + \"\\n\".join(unsupported)\n",
    "        })\n",
    "\n",
    "    return user_content\n",
    "\n",
    "\n",
    "def process_zip(api_key_str: str, system_prompt_str: str, model: str, zip_path: str,\n",
    "                include_inputs_flag: bool, max_items_n: int, seed_n: int) -> str:\n",
    "    job_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    work_dir = f\"job_{job_id}\"\n",
    "    os.makedirs(work_dir, exist_ok=True)\n",
    "\n",
    "    # Extract selected entries here (preserving subfolders)\n",
    "    input_dir = os.path.join(work_dir, \"input\")\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "\n",
    "    # 1) Read zip file list and build groups (folders = one group, root files = one group each)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        all_files = _safe_list_zip_files(zf)\n",
    "        if not all_files:\n",
    "            raise RuntimeError(\"ZIP contains no files (or only folders).\")\n",
    "\n",
    "        groups = _build_groups(all_files)\n",
    "        group_keys = sorted(groups.keys())  # deterministic before sampling\n",
    "\n",
    "        # Random sampling of *groups/items* if requested\n",
    "        if max_items_n and max_items_n > 0 and max_items_n < len(group_keys):\n",
    "            random.seed(seed_n)\n",
    "            selected_keys = sorted(random.sample(group_keys, max_items_n))\n",
    "        else:\n",
    "            selected_keys = group_keys\n",
    "\n",
    "        # Extract only the files needed for selected groups\n",
    "        selected_files = []\n",
    "        for gk in selected_keys:\n",
    "            selected_files.extend(groups[gk])\n",
    "        # de-dup (in case of edge cases)\n",
    "        selected_files = sorted(set(selected_files))\n",
    "\n",
    "        for member in selected_files:\n",
    "            zf.extract(member, input_dir)\n",
    "\n",
    "    # 2) Process each group as ONE payload\n",
    "    rows = []\n",
    "    total = len(selected_keys)\n",
    "\n",
    "    for idx, group_key in enumerate(selected_keys, start=1):\n",
    "        members = groups[group_key]  # list of rel paths (inside zip)\n",
    "        # Build multimodal content containing all files in the group\n",
    "        user_content = _make_user_content_for_group(group_key, input_dir, members)\n",
    "\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt_str},\n",
    "                {\"role\": \"user\", \"content\": user_content}\n",
    "            ]\n",
    "        }\n",
    "        headers = {\"Authorization\": f\"Bearer {api_key_str}\"}\n",
    "\n",
    "        try:\n",
    "            r = requests.post(OPENROUTER_URL, json=payload, headers=headers, timeout=240)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            reply = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            reply = f\"ERROR: {e}\"\n",
    "\n",
    "        rows.append({\"item\": group_key, \"files_in_item\": len(members), \"output\": reply})\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Processed {idx}/{total}: {group_key} (files: {len(members)})\")\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    # 3) Save outputs\n",
    "    output_csv = os.path.join(work_dir, \"output.csv\")\n",
    "    pd.DataFrame(rows).to_csv(output_csv, index=False)\n",
    "\n",
    "    # input.csv should reflect the processed groups and their members\n",
    "    input_rows = []\n",
    "    for group_key in selected_keys:\n",
    "        for rel_name in groups[group_key]:\n",
    "            fpath = os.path.join(input_dir, rel_name)\n",
    "            try:\n",
    "                fsize = os.path.getsize(fpath)\n",
    "            except OSError:\n",
    "                fsize = None\n",
    "            ftype = mimetypes.guess_type(fpath)[0] or \"unknown\"\n",
    "            input_rows.append({\n",
    "                \"item\": group_key,\n",
    "                \"file_name\": rel_name,\n",
    "                \"file_type\": ftype,\n",
    "                \"file_size\": fsize\n",
    "            })\n",
    "\n",
    "    input_csv = os.path.join(work_dir, \"input.csv\")\n",
    "    pd.DataFrame(input_rows).to_csv(input_csv, index=False)\n",
    "\n",
    "    meta = {\n",
    "        \"model\": model,\n",
    "        \"system_prompt\": system_prompt_str,\n",
    "        \"submitted_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"include_inputs\": include_inputs_flag,\n",
    "        \"max_items\": int(max_items_n) if max_items_n is not None else 0,\n",
    "        \"seed\": int(seed_n) if seed_n is not None else 2025,\n",
    "        \"total_files_in_zip\": len(all_files),\n",
    "        \"total_items_in_zip\": len(groups),\n",
    "        \"processed_items\": len(selected_keys),\n",
    "        \"processed_files\": len(input_rows)\n",
    "    }\n",
    "    meta_path = os.path.join(work_dir, \"meta.json\")\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # 4) Create results zip (include only selected inputs if requested)\n",
    "    zip_out = f\"results_{job_id}.zip\"\n",
    "    with zipfile.ZipFile(zip_out, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.write(output_csv, arcname=\"output.csv\")\n",
    "        zf.write(input_csv, arcname=\"input.csv\")\n",
    "        zf.write(meta_path, arcname=\"meta.json\")\n",
    "\n",
    "        if include_inputs_flag:\n",
    "            # include ONLY selected files (folders preserved)\n",
    "            for rel_name in selected_files:\n",
    "                fpath = os.path.join(input_dir, rel_name)\n",
    "                if os.path.isfile(fpath):\n",
    "                    zf.write(fpath, arcname=os.path.join(\"input\", rel_name))\n",
    "\n",
    "    return zip_out\n",
    "\n",
    "\n",
    "def on_run_clicked(_):\n",
    "    if not api_key.value.strip():\n",
    "        print(\"âš ï¸ Please enter your API Key.\")\n",
    "        return\n",
    "\n",
    "    # Resolve zip path from upload or Drive\n",
    "    if upload_method.value == \"Upload (<100MB)\":\n",
    "        if not upload_btn.value:\n",
    "            print(\"âš ï¸ Please upload a ZIP file first.\")\n",
    "            return\n",
    "        fname = list(upload_btn.value.keys())[0]\n",
    "        local_zip = \"input_uploaded.zip\"\n",
    "        with open(local_zip, \"wb\") as f:\n",
    "            f.write(upload_btn.value[fname][\"content\"])\n",
    "        zip_path = local_zip\n",
    "    else:\n",
    "        zp = drive_path.value.strip()\n",
    "        if not zp:\n",
    "            print(\"âš ï¸ Please provide a Google Drive path.\")\n",
    "            return\n",
    "        if not os.path.exists(zp):\n",
    "            drive.mount(\"/content/drive\")\n",
    "        if not os.path.exists(zp):\n",
    "            print(f\"âš ï¸ File not found: {zp}\")\n",
    "            return\n",
    "        zip_path = zp\n",
    "\n",
    "    chosen_model = model_custom.value.strip() if model_custom.value.strip() else model_dropdown.value\n",
    "\n",
    "    try:\n",
    "        result_zip = process_zip(\n",
    "            api_key_str=api_key.value.strip(),\n",
    "            system_prompt_str=system_prompt.value,\n",
    "            model=chosen_model,\n",
    "            zip_path=zip_path,\n",
    "            include_inputs_flag=include_inputs.value,\n",
    "            max_items_n=max_items.value,\n",
    "            seed_n=seed_value.value\n",
    "        )\n",
    "        print(\"âœ… Processing complete. Download your results:\")\n",
    "        colab_files.download(result_zip)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "\n",
    "run_btn.on_click(on_run_clicked)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
